kind: Flow
apiVersion: kai.v1
metadata:
  id: flow.cpu_saturation_detector
  name: "CPU Saturation Detector (PSI-based)"
  description: "Detects real CPU saturation that traditional metrics miss"
  tags: ["cpu", "psi", "performance", "saturation"]
  references:
    - title: "Why CPU% Lies: Using PSI for Real Saturation Detection"
      url: "docs/blog/2024-11-26-why-cpu-percent-lies.md"
spec:
  steps:
    - id: get_cpu_usage
      type: sensor
      ref: cpu.usage
      output:
        saveAs: cpu_data

    - id: get_psi_cpu
      type: sensor
      ref: kernel.psi_cpu
      output:
        saveAs: psi_cpu_data

    - id: get_psi_memory
      type: sensor
      ref: kernel.psi_memory
      output:
        saveAs: psi_memory_data

    - id: get_psi_io
      type: sensor
      ref: kernel.psi_io
      output:
        saveAs: psi_io_data

    - id: get_process_state
      type: sensor
      ref: system.sleep
      with:
        duration: 1
      output:
        saveAs: process_data

    - id: analyze_saturation
      type: agent
      agentType: analysis
      input:
        - fromStep: cpu_data
        - fromStep: psi_cpu_data
        - fromStep: psi_memory_data
        - fromStep: psi_io_data
        - fromStep: process_data
      prompt: |
        You are analyzing a server that users report as "slow" or "timing out".

        Traditional dashboards show:
        - CPU usage: {{ cpu_data.usage }}%
        - Load average: {{ cpu_data.load_avg }}

        But these metrics can be misleading. Analyze the PSI (Pressure Stall Information):

        PSI CPU: {{ psi_cpu_data.stdout }}
        PSI Memory: {{ psi_memory_data.stdout }}
        PSI IO: {{ psi_io_data.stdout }}

        PSI tells you how much time processes spent WAITING (stalled) for resources:
        - some: At least one task was stalled
        - full: All non-idle tasks were stalled

        Example PSI output:
        some avg10=5.00 avg60=3.50 avg300=1.20 total=500000000
        full avg10=2.00 avg60=1.50 avg300=0.80 total=200000000

        Critical thresholds (from production experience):
        - CPU "some" avg10 > 10.0 = Threads waiting for CPU
        - Memory "full" avg10 > 5.0 = Critical memory pressure
        - IO "full" avg10 > 20.0 = Severe IO bottleneck

        IMPORTANT: A server at 50% CPU with high PSI is MORE problematic than
        a server at 80% CPU with low PSI. PSI reveals the hidden contention.

        Determine:
        1. Is there real saturation despite "healthy" CPU%?
        2. What resource is causing the stalls?
        3. Is this a threading issue, memory pressure, or IO bottleneck?
      output:
        saveAs: saturation_analysis

    - id: alert_if_saturated
      type: action
      ref: slack.notify
      condition: "{{ saturation_analysis.confidence > 0.8 }}"
      with:
        channel: "#sre-alerts"
        message: |
          ðŸš¨ CPU Saturation Detected (PSI-based)

          Traditional metrics look healthy:
          - CPU: {{ cpu_data.usage }}%
          - Load: {{ cpu_data.load_avg }}

          But PSI reveals hidden contention:
          - {{ saturation_analysis.root_cause }}

          Affected: {{ saturation_analysis.affected_component }}
          Action: {{ saturation_analysis.recommended_action }}
          Confidence: {{ saturation_analysis.confidence }}
